---
title: "Appendix"
author: "Group 19"
output: pdf_document
---

# Set up

```{r}
#Read in data using the years 2017-2018 
#For reading in the data
library(haven)
#For cross validation
library(boot)
#For filtering out unnecessary data
library(dplyr)
#For best subsets
library(leaps)
#For tables
library(knitr)
#For random forests
library(randomForest)
#For a classification tree
library(tree)
library(ggplot2)
#Reading in the dietary file takes a bit due to its size 
demographics = read_xpt("https://wwwn.cdc.gov/Nchs/Nhanes/2017-2018/P_DEMO.XPT")
bodyMeasures = read_xpt("https://wwwn.cdc.gov/Nchs/Nhanes/2017-2018/P_BMX.XPT")
dietary = read_xpt("https://wwwn.cdc.gov/Nchs/Nhanes/2017-2018/P_DR1IFF.XPT")
oralHealth = read_xpt("https://wwwn.cdc.gov/Nchs/Nhanes/2017-2018/P_OHXREF.XPT")

# Given how long someone has been in the US, determine how much someone weighs?
# Data used for the question:
# How long someone has been in US - demographic data  - DMDYRUSZ
# How much someone weighs - Examination Data - Body Measure - BMXWT
# 
# What contributes to tooth decay? 
# Data used for the question: 
# Oral Health - Recommendation of Care
# Dietary Interview - Individual Foods
```

# Methods

## Shrinkage/Selection

```{r}

```

## 5-Fold Cross Validation

```{r}
#Combine the data sets into one
cvData = merge(demographics, bodyMeasures, by = "SEQN")
#Remove interview-based and weight variables
cvData[["SEQN"]] = NULL
cvData[["SDDSRVYR"]] = NULL
cvData[["RIDSTATR"]] = NULL
cvData[["WTINTPRP"]] = NULL
cvData[["WTMECPRP"]] = NULL
cvData[["BMIWT"]] = NULL
cvData[["BMXBMI"]] = NULL
cvData[["BMDBMIC"]] = NULL
cvData[["FIAPROXY"]] = NULL
cvData[["MIAPROXY"]] = NULL
cvData[["MIAINTRP"]] = NULL
cvData[["SIAPROXY"]] = NULL
cvData[["SDMVPSU"]] = NULL
cvData[["SDMVSTRA"]] = NULL
#Select participants in which a full body measure exam was conducted
cvData = subset(cvData, cvData$BMDSTATS == 1)
cvData[["BMDSTATS"]] = NULL
#Remove "Refused" and "Don't Know" data points
cvData = filter(cvData, DMDYRUSZ != 99)
cvData = filter(cvData, DMDYRUSZ != 77)
cvData = filter(cvData, DMDYRUSZ != 77)
#Remove variables which most if not all observations are NA to avoid excluding
#most or all of the data
cvData[["RIDAGEMN"]] = NULL
cvData[["RIDEXPRG"]] = NULL
cvData[["BMXRECUM"]] = NULL
cvData[["BMIRECUM"]] = NULL
cvData[["BMXHEAD"]] = NULL
cvData[["BMIHEAD"]] = NULL
cvData[["BMIHT"]] = NULL
cvData[["BMILEG"]] = NULL
cvData[["BMIARML"]] = NULL
cvData[["BMIARMC"]] = NULL
cvData[["BMIWAIST"]] = NULL
cvData[["BMIHIP"]] = NULL
cvData = na.omit(cvData)
set.seed(415)

#Forward Selection
forwardSel = regsubsets(BMXWT ~ ., data = cvData, method = "forward")
forwardSum = summary(forwardSel)
#CP
which.min(forwardSum$cp)
coef(forwardSel, 9)
#BIC
which.min(forwardSum$bic)
coef(forwardSel, 7)

#Backward Selection
backwardSel = regsubsets(BMXWT ~ ., data = cvData, method = "backward")
backwardSum = summary(backwardSel)
#CP
which.min(backwardSum$cp)
coef(backwardSel, 9)
#BIC
which.min(backwardSum$bic)
coef(backwardSel, 7)

#Best Subsets Selection
bestSub = regsubsets(BMXWT ~ ., data = cvData)
bestSubSum = summary(bestSub)
#CP
which.min(bestSubSum$cp)
coef(bestSub, 9)
#BIC
which.min(bestSubSum$bic)
coef(bestSub, 7)

#All of the selection methods agree on the model for both the CP and BIC criteria
#so we compare both models selected by CP and BIC.
#The DMDBORN4 variable has a coefficient of 0 so we'll remove it

cpModel = glm(BMXWT ~ RIAGENDR + RIDAGEYR + DMDEDUC2 + AIALANGA + INDFMPIR + BMXLEG
              + BMXWAIST + BMXHIP, data = cvData)
bicModel = glm(BMXWT ~ RIAGENDR + RIDAGEYR + AIALANGA + BMXLEG + BMXWAIST + BMXHIP,
               data = cvData)
cpCV = cv.glm(cvData, cpModel, K = 5)$delta[1]
bicCV = cv.glm(cvData, bicModel, K = 5)$delta[1]

#CV Error Table
cvErrors = c(cpCV, bicCV)
cvTable = matrix(cvErrors, nrow = 1, ncol = 2)
rownames(cvTable) = "5-Fold CV Error"
colnames(cvTable) = c("CP", "BIC")
kable(cvTable)

#The BIC model has a lower cross validation error so that is the preferred model
kable(coef(bicModel), col.names = "Coefficient")

#Variable definition table for the paper
definitions = c("Gender of the particpant", 
                "Age in years at screening", 
                "Language of ACASI interview",
                "Upper leg length (cm)",
                "Waist circumference (cm)",
                "Hip circumference (cm)")
definitionsTable = matrix(definitions, nrow = 6, ncol = 1)
rownames(definitionsTable) = c("RIAGENDR", "RIDAGEYR", "AIALANGA", "BMXLEG", 
                               "BMXWAIST", "BMXHIP")
colnames(definitionsTable) = c("Definition")
kable(definitionsTable)
```

## Bagging

```{r}
#Select the necessary variables
forestData = subset(oralHealth, select = c("SEQN", "OHAROCDT"))
forestData = merge(forestData, dietary, by = "SEQN")
forestData[["SEQN"]] = NULL
forestData[["DR1EXMER"]] = NULL
forestData = na.omit(forestData)
#Remove "Refused" and "Don't Know" data points
forestData = filter(forestData, DR1_040Z != 9)
forestData = filter(forestData, DR1_040Z != 7)
forestData = filter(forestData, DR1FS != 99)
forestData = filter(forestData, DR1_030Z != 99)
forestData = filter(forestData, DR1DRSTZ != 5)
forestData$OHAROCDT = as.factor(forestData$OHAROCDT)
set.seed(415)

rows = nrow(forestData)
cols = ncol(forestData)
sample = sample(seq(rows), size = floor(0.7 * rows))
trainSet = forestData[sample,]
testSet = forestData[-sample,]

#Bagging (this will take few minutes)
bagModel = randomForest(OHAROCDT ~ ., data = trainSet, mtry = cols - 1, 
                        importance = TRUE)
varImpPlot(bagModel, n.var = 15, main = "Variable Importance Plot")

predBag = predict(bagModel, testSet, type = "class") 
table(predBag, testSet$OHAROCDT)
#Percentage of correct predictions
correct = table(predBag, testSet$OHAROCDT)[1] + table(predBag, testSet$OHAROCDT)[4]
total = sum(table(predBag, testSet$OHAROCDT)[1:4])
percCorrect = correct / total 
percCorrect

#Take top important variables and make a model of it then test it with
#Using mean decrease accuracy as the metric, take top 10
importance = sort(importance(bagModel)[,3], decreasing = TRUE)
importance[1:10]
impModel = tree(OHAROCDT ~ DR1DBIH + DR1DAY + WTDR2DPP + WTDRD1PP + DR1IGRMS +
                 DR1_020 + DR1FS + DR1_030Z + DR1IPOTA + DR1IFA, data = trainSet)
#Evaluate the new model
predImp = predict(impModel, testSet, type = "class")
table(predImp, testSet$OHAROCDT)
correct = table(predImp, testSet$OHAROCDT)[1] + table(predImp, testSet$OHAROCDT)[4]
total = sum(table(predImp, testSet$OHAROCDT)[1:4])
percCorrect = correct / total 
percCorrect

#Variable definition table for the paper
definitions = c("Number of days between intake day and the day of family questionnaire administered in the household", 
                "Intake day of the week", 
                "Dietary two-day sample weight", 
                "Dietary day one sample weight", 
                "Gram weight of the food/individual component", 
                "Time of eating occasion (HH:MM)",
                "Source of food",
                "Name of eating occasion",
                "Potassium (mg)",
                "Folic acid (mcg)")
definitionsTable = matrix(definitions, nrow = 10, ncol = 1)
rownames(definitionsTable) = c("DR1DBIH", "DR1DAY", "WTDR2DPP", "WTDRD1PP", 
                               "DR1IGRMS", "DR1_020", "DR1FS", "DR1_030Z",
                               "DR1IPOTA", "DR1IFA")
colnames(definitionsTable) = "Definition"
kable(definitionsTable)
```
