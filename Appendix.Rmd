---
title: "Appendix"
author: "Group 19"
output: pdf_document
---

# Set up

```{r}
#Read in data using the years 2017-2018 
#For reading in the data
library(haven)
#For cross validation
library(boot)
#For filtering out unnecessary data
library(dplyr)
#For best subsets
library(leaps)
#For tables
library(knitr)
#For random forests
library(randomForest)
#For a classification tree
library(tree)
#Reading in the dietary file takes a bit due to its size 
demographics = read_xpt("https://wwwn.cdc.gov/Nchs/Nhanes/2017-2018/P_DEMO.XPT")
bodyMeasures = read_xpt("https://wwwn.cdc.gov/Nchs/Nhanes/2017-2018/P_BMX.XPT")
dietary = read_xpt("https://wwwn.cdc.gov/Nchs/Nhanes/2017-2018/P_DR1IFF.XPT")
oralHealth = read_xpt("https://wwwn.cdc.gov/Nchs/Nhanes/2017-2018/P_OHXREF.XPT")

# Given how long someone has been in the US, determine how much someone weighs?
# Data used for the question:
# How long someone has been in US - demographic data  - DMDYRUSZ
# How much someone weighs - Examination Data - Body Measure - BMXWT
# 
# What contributes to tooth decay? 
# Data used for the question: 
# Oral Health - Recommendation of Care
# Dietary Interview - Individual Foods
```

# Methods

## Shrinkage/Selection

```{r}

```

## 5-Fold Cross Validation

```{r}
#Select the necessary variables
cvData = subset(demographics, select = c("SEQN", "DMDYRUSZ", "RIDAGEYR"))
temp = subset(bodyMeasures, select = c("SEQN", "BMXWT"))
cvData = merge(cvData, temp, by = "SEQN")
cvData[["SEQN"]] = NULL
cvData = na.omit(cvData)
#Remove "Refused" and "Don't Know" data points
cvData = filter(cvData, DMDYRUSZ != 99)
cvData = filter(cvData, DMDYRUSZ != 77)
set.seed(415)

#Cross Validation for an unmodified model
unModel = glm(BMXWT ~ DMDYRUSZ, data = cvData)
unCVError = cv.glm(cvData, unModel, K = 5)$delta[1]

#Cross Validation for a polynomial model
degree = seq(1, 20, by = 1)
cv = numeric(length(degree))
for (d in seq_along(degree)) {
  fit = glm(I(BMXWT^d) ~ DMDYRUSZ, data = cvData)
  cvError = cv.glm(cvData, fit, K = 5)$delta[1]
  cv[d]= cvError
}
#Degree of 1 is the min
minPolyCV = min(cv)

#For the log model
logModel = glm(log(BMXWT) ~ DMDYRUSZ, data = cvData)
logCVError = cv.glm(cvData, logModel, K = 5)$delta[1]

#For the square root model
sqrtModel = glm(sqrt(BMXWT) ~ DMDYRUSZ, data = cvData)
sqrtCVError = cv.glm(cvData, sqrtModel, K = 5)$delta[1]

#For the reciprocal model
recModel = glm(I(1/BMXWT) ~ DMDYRUSZ, data = cvData)
recCVError = cv.glm(cvData, recModel, K = 5)$delta[1]

#Put the cv errors into a table
cvErrors = c(unCVError, minPolyCV, logCVError, sqrtCVError, recCVError)
cvErrorTable = matrix(cvErrors, nrow = 1, ncol = 5)
rownames(cvErrorTable) = "Error Rate"
colnames(cvErrorTable) = c("Unmodified", "Degree 1 Polynomial", "Logged", 
                           "Square Root", "Reciprocal")
kable(cvErrorTable, caption = "Cross Validation Error Rates For Different Models")

#The reciprocal models yields the lowest cross validation error, so it is the
#best model found to represent how much someone weighs given how long they have
#been living in the United States

boxplot(I(1/BMXWT) ~ DMDYRUSZ, data = cvData)
#Predict new observations using the model
#Spent 5 years or less in the U.S.
newData = data.frame(DMDYRUSZ = c(1))
predict.lm(ageModel, newData, interval="confidence")
#Spent 5-15 years in the U.S.
newData = data.frame(DMDYRUSZ = c(2))
predict.lm(ageModel, newData, interval="confidence")
#Spent 15-30 years in the U.S.
newData = data.frame(DMDYRUSZ = c(3))
predict.lm(ageModel, newData, interval="confidence")
#Spent 30 years or more in the U.S.
newData = data.frame(DMDYRUSZ = c(4))
predict.lm(ageModel, newData, interval="confidence")
```

## Bagging

```{r}
#Select the necessary variables
forestData = subset(oralHealth, select = c("SEQN", "OHAROCDT"))
forestData = merge(forestData, dietary, by = "SEQN")
forestData[["SEQN"]] = NULL
forestData[["DR1EXMER"]] = NULL
forestData = na.omit(forestData)
#Remove "Refused" and "Don't Know" data points
forestData = filter(forestData, DR1_040Z != 9)
forestData = filter(forestData, DR1_040Z != 7)
forestData = filter(forestData, DR1FS != 99)
forestData = filter(forestData, DR1_030Z != 99)
forestData = filter(forestData, DR1DRSTZ != 5)
forestData$OHAROCDT = as.factor(forestData$OHAROCDT)
set.seed(415)

rows = nrow(forestData)
cols = ncol(forestData)
sample = sample(seq(rows), size = floor(0.7 * rows))
trainSet = forestData[sample,]
testSet = forestData[-sample,]

#Bagging (this will take few minutes)
bagModel = randomForest(OHAROCDT ~ ., data = trainSet, mtry = cols - 1, 
                        importance = TRUE)
plot(bagModel)
varImpPlot(bagModel, main = "Variable Importance Plot")

predBag = predict(bagModel, testSet, type = "class") 
table(predBag, testSet$OHAROCDT)
#Percentage of correct predictions
correct = table(predBag, testSet$OHAROCDT)[1] + table(predBag, testSet$OHAROCDT)[4]
total = sum(table(predBag, testSet$OHAROCDT)[1:4])
percCorrect = correct / total 
percCorrect

#Take top important variables and make a model of it then test it with
#Using mean decrease accuracy as the metric, take top 10
importance = sort(importance(bagModel)[,3], decreasing = TRUE)
importance[1:10]
impModel = tree(OHAROCDT ~ DR1DBIH + DR1DAY + WTDR2DPP + WTDRD1PP + DR1IGRMS +
                 DR1_020 + DR1FS + DR1_030Z + DR1IPOTA + DR1IFA, data = trainSet)
#Evaluate the new model
predImp = predict(impModel, testSet, type = "class")
table(predImp, testSet$OHAROCDT)
correct = table(predImp, testSet$OHAROCDT)[1] + table(predImp, testSet$OHAROCDT)[4]
total = sum(table(predImp, testSet$OHAROCDT)[1:4])
percCorrect = correct / total 
percCorrect

#Variable definition table for the paper
definitions = c("Number of days between intake day and the day of family questionnaire administered in the household", 
                "Intake day of the week", 
                "Dietary two-day sample weight", 
                "Dietary day one sample weight", 
                "Gram weight of the food/individual component", 
                "Time of eating occasion (HH:MM)",
                "Source of food",
                "Name of eating occasion",
                "Potassium (mg)",
                "Folic acid (mcg)")
definitionsTable = matrix(definitions, nrow = 10, ncol = 1)
rownames(definitionsTable) = c("DR1DBIH", "DR1DAY", "WTDR2DPP", "WTDRD1PP", 
                               "DR1IGRMS", "DR1_020", "DR1FS", "DR1_030Z",
                               "DR1IPOTA", "DR1IFA")
colnames(definitionsTable) = "Definition"
kable(definitionsTable)
```
