---
title: "Appendix"
author: "Group 19"
output: pdf_document
---

# Set up

```{r}
#Read in data using the years 2017-2018 
#For reading in the data
library(haven)
#For cross validation
library(boot)
#For filtering out unnecessary data
library(dplyr)
#For best subsets
library(leaps)
#For tables
library(knitr)
#For random forests
library(randomForest)
#Reading in the dietary file takes a bit due to its size 
#(also could be the network speed/connection)
demographics = read_xpt("https://wwwn.cdc.gov/Nchs/Nhanes/2017-2018/P_DEMO.XPT")
bodyMeasures = read_xpt("https://wwwn.cdc.gov/Nchs/Nhanes/2017-2018/P_BMX.XPT")
dietary = read_xpt("https://wwwn.cdc.gov/Nchs/Nhanes/2017-2018/P_DR1IFF.XPT")
oralHealth = read_xpt("https://wwwn.cdc.gov/Nchs/Nhanes/2017-2018/P_OHXREF.XPT")

# Given how long someone has been in the US, determine how much someone weighs?
# Data used for the question:
# How long someone has been in US - demographic data  - DMDYRUSZ
# How much someone weighs - Examination Data - Body Measure - BMXWT
# 
# What contributes to tooth decay? 
# Data used for the question: 
# Oral Health - Recommendation of Care
# Dietary Interview - Individual Foods
```

# Methods

## Shrinkage/Selection

```{r}

```

## 5-Fold Cross Validation

```{r}
#Select the necessary variables
cvData = subset(demographics, select = c("SEQN", "DMDYRUSZ"))
temp = subset(bodyMeasures, select = c("SEQN", "BMXWT"))
cvData = merge(cvData, temp, by = "SEQN")
cvData[["SEQN"]] = NULL
cvData = na.omit(cvData)
#Remove "Refused" and "Don't Know" data points
cvData = filter(cvData, DMDYRUSZ != 99)
cvData = filter(cvData, DMDYRUSZ != 77)

#Cross Validation for an unmodified model
unModel = glm(BMXWT ~ DMDYRUSZ, data = cvData)
unCVError = cv.glm(cvData, unModel, K = 5)$delta[1]

#Cross Validation for a polynomial model
degree = seq(1, 20, by = 1)
cv = numeric(length(degree))
for (d in seq_along(degree)) {
  fit = glm(I(BMXWT^d) ~ DMDYRUSZ, data = cvData)
  cvError = cv.glm(cvData, fit, K = 5)$delta[1]
  cv[d]= cvError
}
#Degree of 1 is the min
minPolyCV = min(cv)
plot(degree, cv)

#For the log model
logModel = glm(log(BMXWT) ~ DMDYRUSZ, data = cvData)
logCVError = cv.glm(cvData, logModel, K = 5)$delta[1]

#For the square root model
sqrtModel = glm(sqrt(BMXWT) ~ DMDYRUSZ, data = cvData)
sqrtCVError = cv.glm(cvData, sqrtModel, K = 5)$delta[1]

#For the reciprocal model
recModel = glm(I(1/BMXWT) ~ DMDYRUSZ, data = cvData)
recCVError = cv.glm(cvData, recModel, K = 5)$delta[1]

cvErrors = c(unCVError, minPolyCV, logCVError, sqrtCVError, recCVError)
cvErrorTable = matrix(cvErrors, nrow = 1, ncol = 5)
rownames(cvErrorTable) = "Error Rate"
colnames(cvErrorTable) = c("Unmodified", "Degree 1 Polynomial", "Logged", 
                           "Square Root", "Reciprocal")
kable(cvErrorTable, caption = "Cross Validation Error Rates For Different Models")
```

## Random Forests

```{r}
#Select the necessary variables
forestData = subset(oralHealth, select = c("SEQN", "OHAROCDT"))
forestData = merge(forestData, dietary, by = "SEQN")
forestData[["SEQN"]] = NULL
forestData = na.omit(forestData)
#Remove "Refused" and "Don't Know" data points
forestData = filter(forestData, DR1_040Z != 9)
forestData = filter(forestData, DR1_040Z != 7)
forestData = filter(forestData, DR1FS != 99)
forestData = filter(forestData, DR1_030Z != 99)
forestData = filter(forestData, DR1DRSTZ != 5)
forestData$OHAROCDT = as.factor(forestData$OHAROCDT)

rows = nrow(forestData)
cols = ncol(forestData)
sample = sample(seq(rows), size = floor(0.7 * rows))
trainSet = forestData[sample,]
testSet = forestData[-sample,]

#Bagging (this will take few minutes)
bag = randomForest(
  OHAROCDT ~ . ,        # Model formula
  data = trainSet,    # Training data
  mtry = cols - 1, # Use all columns
  importance = TRUE)      # Return feature importance measures
bag
summary(bag)
plot(bag)
importance(bag)
varImpPlot(bag)

predBag = predict(bag, testSet, type = "class") 
table(predBag, testSet$OHAROCDT)
#Percentage of correct predictions
(11008+37)/(11008+19+37)

#Prune
```
